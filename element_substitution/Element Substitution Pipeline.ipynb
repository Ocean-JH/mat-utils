{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Elemental Substitution Pipeline\n",
    "This notebook demonstrates the elemental substitution pipeline for generating new materials in Ge-Sb-Te system.\n",
    "\n",
    "Author: ***Jianghai@BUAA***"
   ],
   "id": "be2701aab457812b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. **Data Mining from Materials Project**\n",
    "Query materials from the Materials Project database that satisfy the valence constraint for Ge–Sb–Te ternary systems:\n",
    "$$\n",
    "2x+3y-2z=0\n",
    "$$\n",
    "where $x$, $y$, and $z$ are the number of Ge, Sb, and Te atoms in the formula, respectively.\n",
    "\n",
    "**Key Output**:\n",
    "A CSV file containing the filtered material entries that obey the charge balance rule based on nominal valences:\n",
    "\n",
    "- Ge: +2\n",
    "- Sb: +3\n",
    "- Te: −2"
   ],
   "id": "5ce25877d72fe400"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from math import gcd\n",
    "from mp_api.client import MPRester"
   ],
   "id": "5b99c10fe0867eed"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "API_KEY = \"type_your_API_key_here\"  # Replace with your Materials Project API key\n",
    "\n",
    "\"\"\"\n",
    "            Periodic Table of Elements\n",
    "\"\"\"\n",
    "# Elements = ['H', 'He',\n",
    "#             'Li', 'Be', 'B', 'C', 'N', 'O', 'F', 'Ne',\n",
    "#             'Na', 'Mg', 'Al', 'Si', 'P', 'S', 'Cl', 'Ar',\n",
    "#             'K', 'Ca', 'Sc', 'Ti', 'V', 'Cr', 'Mn', 'Fe', 'Co', 'Ni', 'Cu', 'Zn', 'Ga', 'Ge', 'As', 'Se', 'Br', 'Kr',\n",
    "#             'Rb', 'Sr', 'Y', 'Zr', 'Nb', 'Mo', 'Tc', 'Ru', 'Rh', 'Pd', 'Ag', 'Cd', 'In', 'Sn', 'Sb', 'Te', 'I', 'Xe',\n",
    "#             'Cs', 'Ba', 'Hf', 'Ta', 'W', 'Re', 'Os', 'Ir', 'Pt', 'Au', 'Hg', 'Tl', 'Pb', 'Bi', 'Po', 'At', 'Rn',\n",
    "#             'Fr', 'Ra', 'Rf', 'Db', 'Sg', 'Bh', 'Hs', 'Mt', 'Ds', 'Rg', ' Cn', 'Nh', 'Fl', 'Mc', 'Lv', 'Ts', 'Og',\n",
    "#             'La', 'Ce', 'Pr', 'Nd', 'Pm', 'Sm', 'Eu', 'Gd', 'Tb', 'Dy', 'Ho', 'Er', 'Tm', 'Yb', 'Lu',\n",
    "#             'Ac', 'Th', 'Pa', 'U', ' Np', 'Pu', 'Am', 'Cm', 'Bk', 'Cf', 'Es', 'Fm', 'Md', 'No', 'Lr']\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "            Stoichiometry satisfied the valency constraint\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def coprime(a, b, c):\n",
    "    return gcd(a, b, c) == 1\n",
    "\n",
    "\n",
    "Stoichiometry = []\n",
    "for x in range(1, 20):\n",
    "    for y in range(1, 20):\n",
    "        for z in range(1, 20):\n",
    "            if 2 * x + 3 * y - 2 * z == 0:\n",
    "                if coprime(x, y, z):\n",
    "                    Stoichiometry.append([x, y, z])\n",
    "\n",
    "\"\"\"\n",
    "            Data retrieval\n",
    "\"\"\"\n",
    "for formula in Stoichiometry:\n",
    "    with MPRester(API_KEY) as mpr:\n",
    "        # list_of_available_fields = mpr.materials.summary.available_fields\n",
    "        # print(list_of_available_fields)\n",
    "        \"\"\"\n",
    "        ['builder_meta', 'nsites', 'elements', 'nelements', 'composition', 'composition_reduced', 'formula_pretty',\n",
    "        'formula_anonymous', 'chemsys', 'volume', 'density', 'density_atomic', 'symmetry', 'property_name',\n",
    "        'material_id', 'deprecated', 'deprecation_reasons', 'last_updated', 'origins', 'warnings', 'structure',\n",
    "        'task_ids', 'uncorrected_energy_per_atom', 'energy_per_atom', 'formation_energy_per_atom', 'energy_above_hull',\n",
    "        'is_stable', 'equilibrium_reaction_energy_per_atom', 'decomposes_to', 'xas', 'grain_boundaries', 'band_gap',\n",
    "        'cbm', 'vbm', 'efermi', 'is_gap_direct', 'is_metal', 'es_source_calc_id', 'bandstructure', 'dos',\n",
    "        'dos_energy_up', 'dos_energy_down', 'is_magnetic', 'ordering', 'total_magnetization',\n",
    "        'total_magnetization_normalized_vol', 'total_magnetization_normalized_formula_units', 'num_magnetic_sites',\n",
    "        'num_unique_magnetic_sites', 'types_of_magnetic_species', 'k_voigt', 'k_reuss', 'k_vrh', 'g_voigt', 'g_reuss',\n",
    "        'g_vrh', 'universal_anisotropy', 'homogeneous_poisson', 'e_total', 'e_ionic', 'e_electronic', 'n', 'e_ij_max',\n",
    "        'weighted_surface_energy_EV_PER_ANG2', 'weighted_surface_energy', 'weighted_work_function',\n",
    "        'surface_anisotropy', 'shape_factor', 'has_reconstructed', 'possible_species', 'has_props', 'theoretical',\n",
    "        'database_IDs']\n",
    "        \"\"\"\n",
    "\n",
    "        docs = mpr.materials.summary.search(formula=[\"*{}*{}*{}\".format(formula[0], formula[1], formula[2])],\n",
    "                                            fields=['material_id', 'database_IDs', 'nelements', 'chemsys',\n",
    "                                                    'formula_anonymous', 'formula_pretty', 'composition',\n",
    "                                                    'symmetry', 'energy_per_atom', 'formation_energy_per_atom',\n",
    "                                                    'energy_above_hull', 'is_stable', 'theoretical', 'volume',\n",
    "                                                    'density', 'possible_species', 'decomposes_to',\n",
    "                                                    'deprecated', 'origins', 'warnings', 'last_updated',\n",
    "                                                    'structure'])\n",
    "\n",
    "        MP_Prototype_Info = [\n",
    "            [doc.material_id, doc.database_IDs, doc.nelements, doc.chemsys, doc.formula_anonymous,\n",
    "             doc.formula_pretty, doc.composition, doc.symmetry, doc.energy_per_atom,\n",
    "             doc.formation_energy_per_atom, doc.energy_above_hull, doc.is_stable, doc.theoretical, doc.volume,\n",
    "             doc.density, doc.possible_species, doc.decomposes_to, doc.deprecated, doc.origins, doc.warnings,\n",
    "             doc.last_updated] for doc in docs]\n",
    "\n",
    "    MP_Prototype_Info = pd.DataFrame(MP_Prototype_Info,\n",
    "                                     columns=['material_id', 'database_IDs', 'nelements', 'chemsys',\n",
    "                                              'formula_anonymous', 'formula_pretty', 'composition', 'symmetry',\n",
    "                                              'energy_per_atom', 'formation_energy_per_atom', 'energy_above_hull',\n",
    "                                              'is_stable', 'theoretical', 'volume', 'density', 'possible_species',\n",
    "                                              'decomposes_to', 'deprecated', 'origins', 'warnings', 'last_updated'])\n",
    "\n",
    "    if not os.path.exists(r'~\\MP_Prototype_Info.csv'):\n",
    "        MP_Prototype_Info.to_csv(r'~\\MP_Prototype_Info.csv',\n",
    "                                 mode='a', index=False)\n",
    "    else:\n",
    "        MP_Prototype_Info.to_csv(r'~\\MP_Prototype_Info.csv',\n",
    "                                 mode='a', index=False, header=False)\n",
    "\n",
    "info = pd.read_csv(r'~\\MP_Prototype_Info.csv')\n",
    "info_symmetry = info['symmetry'].str.split('\\'', expand=True)[[1, 3, 4, 5]]\n",
    "info_spg = info_symmetry[4].str.split('=', expand=True)[1].str.split(expand=True)[0]\n",
    "info_sym = pd.concat([info_symmetry, info_spg], axis=1)\n",
    "info = pd.concat([info, info_sym], axis=1)\n",
    "info = info.rename(columns={0: 'space_group_number', 1: 'crystal_system', 3: 'space_group', 5: 'point_group'})\n",
    "info.drop([4, 'symmetry'], axis=1, inplace=True)\n",
    "info.to_csv(r'~\\MP_Prototype_Info.csv', mode='w', index=False)\n"
   ],
   "id": "72871fbed19c8242"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. **Element Substitution Based on Stoichiometry**\n",
    "Perform element substitution in prototype structures (POSCARs) to systematically generate Ge–Sb–Te structures according to specified stoichiometries.\n"
   ],
   "id": "54b230a257bf7683"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import math\n",
    "import linecache"
   ],
   "id": "9248748dee32934a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def seq_element(stoichiometry, comp):\n",
    "    \"\"\"\n",
    "            Sort the elements by stoichiometry\n",
    "    \"\"\"\n",
    "    element_seq = []\n",
    "    for idx in range(3):\n",
    "        for key, value in stoichiometry.items():\n",
    "            if value == comp[idx]:\n",
    "                element_seq.append(key)\n",
    "                stoichiometry.update({key: '0'})\n",
    "                break\n",
    "    return element_seq\n",
    "\n",
    "\n",
    "# Access to the directory of raw files\n",
    "dirs = os.listdir(r'~\\Stoichiometry')\n",
    "# Create directory of destination files\n",
    "os.mkdir(r'~\\ElementSub')\n",
    "for dir in dirs:\n",
    "    # Create subdirectories of destination files\n",
    "    os.mkdir(r'~\\ElementSub\\{}'.format(dir))\n",
    "    # Access to raw filenames\n",
    "    files = os.listdir(r'~\\Stoichiometry\\\\' + dir)\n",
    "\n",
    "    for i in range(len(files)):\n",
    "        # Concatenate to get filenames\n",
    "        fileName = r'~\\Stoichiometry\\\\' + dir + '\\\\' + files[i]\n",
    "\n",
    "        # Bind target elements to the corresponding stoichiometry\n",
    "        element = ['Ge', 'Sb', 'Te']\n",
    "        composition = dir.split(\"-\")\n",
    "        stoichiometry = {element[i]: composition[i] for i in range(3)}\n",
    "\n",
    "        # Get stoichiometry of raw files and reduce it\n",
    "        comp = linecache.getline(fileName, 7).split()\n",
    "        comp_int = [int(i) for i in comp]\n",
    "        gcd = math.gcd(comp_int[0], comp_int[1], comp_int[2])         # Calculate the greatest common divisor (GCD)\n",
    "        if gcd != 1:\n",
    "            comp_int = [int(i / gcd) for i in comp_int]\n",
    "            comp = [str(i) for i in comp_int]\n",
    "        # Get the elements sorted correctly\n",
    "        seq_ele = seq_element(stoichiometry, comp)\n",
    "\n",
    "        # Copy the contents of raw files\n",
    "        file_ini = open(fileName, \"r\")\n",
    "        content = file_ini.read()\n",
    "        file_ini.close()\n",
    "\n",
    "        # Modify the corresponding elements and write to destination files\n",
    "        with open(r'~\\ElementSub\\\\' + dir + '\\\\' + '{}-{}-POSCAR'.format(files[i].split(\"_\")[0], files[i].split(\"_\")[1].split(\".\")[0]), \"w\") as file_processed:\n",
    "            ini_ele = linecache.getline(fileName, 6).split()\n",
    "            temp_ele = ['!!!', '@@@', '###']\n",
    "            # Corresponding elements substitution\n",
    "            for x in range(3):\n",
    "                # Avoid interference\n",
    "                if len(ini_ele[x]) == 2:\n",
    "                    content = content.replace('{}'.format(ini_ele[x]), '{}'.format(temp_ele[x]))\n",
    "            for y in range(3):\n",
    "                content = content.replace('{}'.format(ini_ele[y]), '{}'.format(temp_ele[y]))\n",
    "            for z in range(3):\n",
    "                content = content.replace('{}'.format(temp_ele[z]), '{}'.format(seq_ele[z]))\n",
    "            file_processed.write(content)\n",
    "            file_processed.close()\n"
   ],
   "id": "9c52bdb296c77df5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. **Permutation of Equivalent Compositions**\n",
    "For stoichiometries with two or more identical atomic counts (i.e., 2–2–5), generate permutationally equivalent structures by swapping elements."
   ],
   "id": "79ccffd15be100ee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "dirs = os.listdir(r'~\\ElementSub')\n",
    "\n",
    "for dir in dirs:\n",
    "    composition = dir.split(\"-\")\n",
    "    # Check for duplicate elements\n",
    "    if len(composition) != len(set(composition)):\n",
    "        # Access to the directory of permutation files\n",
    "        os.mkdir(r'~\\ElementSub\\{}-{}-{}_Permutation'.format(*composition))\n",
    "        files = os.listdir(r'~\\ElementSub\\\\' + dir)\n",
    "\n",
    "        for i in range(len(files)):\n",
    "            fileName = r'~\\ElementSub\\\\' + dir + '\\\\' + files[i]\n",
    "            file_ini = open(fileName, \"r\")\n",
    "            content = file_ini.read()\n",
    "            file_ini.close()\n",
    "\n",
    "            with open(r'~\\ElementSub\\{}-{}-{}_Permutation'.format(*composition) + '\\\\' + '{}_permutation'.format(files[i]), \"w\") as file_permutated:\n",
    "                content = content.replace('Ge', 'G_e').replace('Sb', 'Ge').replace('G_e', 'Sb')\n",
    "                file_permutated.write(content)\n",
    "                file_permutated.close()\n"
   ],
   "id": "2156e8ed0ba9074a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. Preparing DFT Calculation Folders\n",
    "Organize the substituted structures into a directory structure suitable for VASP DFT calculations."
   ],
   "id": "fbc464988cd0d793"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "import shutil",
   "id": "a30ea4e52dfd8898"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Backup raw_folder\n",
    "ini_path = r\"~\\ElementSub\"\n",
    "main_work_path = r\"~\\ElementSub_Calc\"\n",
    "shutil.copytree(ini_path, main_work_path)\n",
    "\n",
    "\n",
    "dirs = os.listdir(main_work_path)\n",
    "\n",
    "for dir in dirs:\n",
    "    workdir = os.path.join(main_work_path, dir)\n",
    "    files = os.listdir(workdir)\n",
    "\n",
    "    for file in files:\n",
    "        fileName = file.split(\"-\")\n",
    "        Calc_path = os.path.join(workdir, \"{}-{}-{}\".format(fileName[0], fileName[1], fileName[2]))\n",
    "        os.mkdir(Calc_path)\n",
    "        shutil.move(os.path.join(workdir, file), os.path.join(Calc_path, \"POSCAR\"))\n"
   ],
   "id": "499ef031c7e750c6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5. **Analysis of DFT Calculation Results**\n",
    "### 5.1 Convergence Check\n",
    "### 5.2 Data Extraction and Processing\n",
    "### 5.3 Data Selection\n",
    "### 5.4 Convex Hull Analysis & Visualization"
   ],
   "id": "77e03c408290a03c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from scipy.spatial import ConvexHull\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pymatgen.core import Structure\n",
    "from pymatgen.io.vasp.outputs import Oszicar, Vasprun\n",
    "from pymatgen.symmetry.analyzer import SpacegroupAnalyzer"
   ],
   "id": "f99de67946cd2bc5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def check_convergence(calc_dir):\n",
    "    file = os.path.join(calc_dir, 'OUTCAR')\n",
    "    with open(file, 'r') as f:\n",
    "        content = f.read()\n",
    "        return 'reached required accuracy' in content\n",
    "\n",
    "\n",
    "def data_extraction(root_dir=None, depth=2):\n",
    "    if root_dir is None:\n",
    "        root_dir = r'~'\n",
    "\n",
    "    data_info = pd.DataFrame(columns=['group',\n",
    "                                      'parent',\n",
    "                                      'Ge', 'Sb', 'Te',\n",
    "                                      'space_group_symbol',\n",
    "                                      'space_group_number',\n",
    "                                      'convergence',\n",
    "                                      'energy_per_atom',\n",
    "                                      'formation_energy_per_atom'])\n",
    "\n",
    "    for root, dirs, files in os.walk(root_dir):\n",
    "        cur_depth = root.count(os.sep) - root_dir.count(os.sep)\n",
    "        if cur_depth == depth:\n",
    "            if 'OUTCAR' in files and 'OSZICAR' in files and 'vasprun.xml' in files:\n",
    "                group = root.split('\\\\')[-2]\n",
    "                parent = root.split('\\\\')[-1]\n",
    "                convergence = check_convergence(root)\n",
    "                species = linecache.getline(os.path.join(root, 'POSCAR'), 6).split()\n",
    "                stoichiometry = linecache.getline(os.path.join(root, 'POSCAR'), 7).split()\n",
    "                composition = {'Ge': '0',\n",
    "                               'Sb': '0',\n",
    "                               'Te': '0'}\n",
    "                composition.update({species[i]: stoichiometry[i] for i in range(len(species))})\n",
    "\n",
    "                xml_path = os.path.join(root, 'vasprun.xml')\n",
    "                oszicar_path = os.path.join(root, 'OSZICAR')\n",
    "                try:\n",
    "                    dataset = Vasprun(xml_path)\n",
    "\n",
    "                    with open(os.path.join(os.path.dirname(root_dir), 'EleSub_dataset.json'), 'a',\n",
    "                              newline='\\n') as file:\n",
    "                        json.dump(dataset.as_dict(), file)\n",
    "                        file.write('\\n')\n",
    "\n",
    "                    n_atoms = len(dataset.ionic_steps[0][\"structure\"])\n",
    "                    energy = Oszicar(oszicar_path).final_energy\n",
    "                    energy_per_atom = energy / n_atoms\n",
    "\n",
    "                    ge_energy_per_atom = -4.518072\n",
    "                    sb_energy_per_atom = -4.141693\n",
    "                    te_energy_per_atom = -3.141757\n",
    "\n",
    "                    formation_energy_per_atom = (energy - (int(composition['Ge']) * ge_energy_per_atom +\n",
    "                                                           int(composition['Sb']) * sb_energy_per_atom +\n",
    "                                                           int(composition['Te']) * te_energy_per_atom)) / (\n",
    "                                                        int(composition['Ge']) + int(composition['Sb']) + int(\n",
    "                                                    composition['Te']))\n",
    "\n",
    "                    structure = Structure.from_file(os.path.join(root, 'CONTCAR'))\n",
    "                    spa = SpacegroupAnalyzer(structure)\n",
    "                    spg_symbol = spa.get_space_group_symbol()\n",
    "                    spg_number = spa.get_space_group_number()\n",
    "\n",
    "                    data = {'group': group,\n",
    "                            'parent': parent,\n",
    "                            'Ge': int(composition['Ge']),\n",
    "                            'Sb': int(composition['Sb']),\n",
    "                            'Te': int(composition['Te']),\n",
    "                            'space_group_symbol': spg_symbol,\n",
    "                            'space_group_number': spg_number,\n",
    "                            'convergence': convergence,\n",
    "                            'energy_per_atom': energy_per_atom,\n",
    "                            'formation_energy_per_atom': formation_energy_per_atom}\n",
    "\n",
    "                    data = pd.DataFrame(data, index=[0])\n",
    "                    data_info = pd.concat([data_info, data], ignore_index=True)\n",
    "                except:\n",
    "                    print('Error in {}, skipping...'.format(root))\n",
    "                    continue\n",
    "\n",
    "    data_info.to_csv(os.path.join(os.path.dirname(root_dir), 'EleSub_dataset.csv'), index=False)\n",
    "\n",
    "\n",
    "def data_processing(data_path):\n",
    "    data_info = pd.read_csv(data_path)\n",
    "    data_info['group'] = data_info['group'].astype(str)\n",
    "    data_info['convergence'] = data_info['convergence'].astype(str)\n",
    "    data_info = data_info[data_info['convergence'].str.contains('True')]\n",
    "    data_info.sort_values(by=['formation_energy_per_atom'], inplace=True)\n",
    "\n",
    "    data_info[['Ge', 'Sb', 'Te']] = data_info[['Ge', 'Sb', 'Te']].astype(int)\n",
    "    data_info['m'] = data_info['Ge']\n",
    "    data_info['n'] = data_info['Sb'] / 2\n",
    "    data_info['n'] = data_info['n'].astype(int)\n",
    "    data_info['x'] = data_info['m'] / (data_info['m'] + data_info['n'])\n",
    "    data_info['y'] = data_info['formation_energy_per_atom']\n",
    "\n",
    "    data_info.to_csv(r'~\\valid_data.csv', index=False)\n",
    "\n",
    "\n",
    "def select_data(data_path):\n",
    "    data_info = pd.read_csv(data_path)\n",
    "    data_info = data_info[data_info['Ehull'] < 0.13]\n",
    "    data_info = data_info[data_info['formation_energy_per_atom'] < 0]\n",
    "    data_info = data_info[data_info['space_group_number'] != 1]\n",
    "    data_info = data_info[~data_info['group'].str.contains('1-2-4')]\n",
    "    data_info = data_info[~data_info['group'].str.contains('1-4-7')]\n",
    "    data_info = data_info[~data_info['group'].str.contains('1-6-10')]\n",
    "    data_info = data_info[~data_info['group'].str.contains('2-2-5')]\n",
    "    data_info = data_info[~data_info['group'].str.contains('2-2-5_Permutation')]\n",
    "\n",
    "    data_info.to_csv(r'~\\EleSub_selected.csv', index=False)\n",
    "\n",
    "\n",
    "def convex_hull(data_path):\n",
    "    data_info = pd.read_csv(data_path)\n",
    "    data = data_info[['x', 'y']]\n",
    "    edge = [[0, -0.1202678],\n",
    "            [1, -0.0942086]]\n",
    "    data = data._append(pd.DataFrame(edge, columns=data.columns))\n",
    "    data.reset_index(inplace=True, drop=True)\n",
    "    pts = np.array(data)\n",
    "\n",
    "    '''\n",
    "                Convex hull determination\n",
    "    '''\n",
    "    hull = ConvexHull(pts)\n",
    "\n",
    "    '''\n",
    "                Set of convex hull vertices\n",
    "    '''\n",
    "    hull_vts_all = []\n",
    "    for pt in hull.vertices:\n",
    "        vertex = pts[pt]\n",
    "        hull_vts_all.append(vertex)\n",
    "    hull_vts_all = pd.DataFrame(hull_vts_all)\n",
    "\n",
    "    hull_vts_negative = hull_vts_all[~(hull_vts_all[[1]] > 0).any(axis=1)]\n",
    "\n",
    "    '''\n",
    "                Equation determination\n",
    "    '''\n",
    "    HULL = ConvexHull(hull_vts_negative)\n",
    "\n",
    "    HULL_Eqs = pd.DataFrame(HULL.equations)\n",
    "    HULL_Eqs = np.array(HULL_Eqs)\n",
    "    HULL_Eqs = np.delete(HULL_Eqs, [0], axis=0)\n",
    "\n",
    "    '''\n",
    "                Calculation of E_hull\n",
    "    '''\n",
    "    a, b, c, x, y = [], [], [], [], []\n",
    "\n",
    "    for i in range(len(HULL_Eqs)):\n",
    "        a_i = HULL_Eqs[i][0]\n",
    "        a.append(a_i)\n",
    "        b_i = HULL_Eqs[i][1]\n",
    "        b.append(b_i)\n",
    "        c_i = HULL_Eqs[i][2]\n",
    "        c.append(c_i)\n",
    "\n",
    "    for j in range(len(pts)):\n",
    "        x_j = pts[j][0]\n",
    "        x.append(x_j)\n",
    "        y_j = pts[j][1]\n",
    "        y.append(y_j)\n",
    "\n",
    "    e_on_hull_set = []\n",
    "    for i in range(len(pts)):\n",
    "        for j in range(len(HULL_Eqs)):\n",
    "            e_on_hull = -(x[i] * a[j] + c[j]) / b[j]\n",
    "            e_on_hull_set.append(e_on_hull)\n",
    "    e_on_hull_set = pd.DataFrame(np.array(e_on_hull_set).reshape(len(pts), len(HULL_Eqs)))\n",
    "    e_on_hull = e_on_hull_set.max(axis=1)  # Select the maximum value as convex hull energy\n",
    "\n",
    "    eform = data_info['y']\n",
    "    ehull_set = []\n",
    "    for i in range(len(eform)):\n",
    "        ehull = eform[i] - e_on_hull[i]  # Calculation of E_hull\n",
    "        ehull_set.append(ehull)\n",
    "\n",
    "    '''\n",
    "                File output\n",
    "    '''\n",
    "    data_info['Ehull'] = ehull_set\n",
    "    data_info = pd.DataFrame(data_info)\n",
    "    data_info.to_csv(r'~\\EleSub_Energy_above_Hull.csv', index=False)\n",
    "\n",
    "\n",
    "def plot_convex_hull(data_path):\n",
    "    data = pd.read_csv(data_path)\n",
    "    x1 = data['x']\n",
    "    y1 = data['y']\n",
    "\n",
    "    seeds_path = r'F:\\Dataset\\mp_GST_Data.csv'\n",
    "    seeds = pd.read_csv(seeds_path)\n",
    "    seeds = seeds[seeds['Ge'] + seeds['Sb'] / 2 * 3 == seeds['Te']]\n",
    "    seeds['convergence'] = seeds['convergence'].astype(str)\n",
    "    seeds = seeds[seeds['convergence'].str.contains('True')]\n",
    "    seeds = seeds[['Ge', 'Sb', 'Te', 'space_group_symbol', 'space_group_number', 'formation_energy_per_atom']]\n",
    "    seeds[['Ge', 'Sb', 'Te']] = seeds[['Ge', 'Sb', 'Te']].astype(int)\n",
    "    seeds['m'] = seeds['Ge']\n",
    "    seeds['n'] = seeds['Sb'] / 2\n",
    "    seeds['n'] = seeds['n'].astype(int)\n",
    "    seeds['x'] = seeds['m'] / (seeds['m'] + seeds['n'])\n",
    "    seeds['y'] = seeds['formation_energy_per_atom']\n",
    "\n",
    "    # Metastable cubic structure\n",
    "    cubic_data = np.array([[0, -0.02081418],\n",
    "                           [0.333333, -0.07518477],\n",
    "                           [0.5, -0.052255621],\n",
    "                           [0.666667, -0.071077905],\n",
    "                           [1, -0.075879095]])\n",
    "\n",
    "    x2 = seeds['x']\n",
    "    y2 = seeds['y']\n",
    "\n",
    "    hull_data = data[['x', 'y']]\n",
    "    hull_seeds = seeds[['x', 'y']]\n",
    "    hull_data = pd.concat([hull_data, hull_seeds])\n",
    "    hull_data = hull_data[~(hull_data[['y']] > 0).any(axis=1)]\n",
    "\n",
    "    hull_data = np.array(hull_data)\n",
    "    hull = ConvexHull(hull_data)\n",
    "\n",
    "    simplices = hull.simplices\n",
    "    simplices = np.delete(simplices, [0, 1, 2, 4, 5, 6, 7, 8], axis=0)\n",
    "\n",
    "    plt.figure(figsize=(16, 9))\n",
    "    ax = plt.subplot(111)\n",
    "    plt.scatter(x1, y1, color='None', marker='d', edgecolor='teal', s=100, alpha=0.25, label='Elemental Substitution')\n",
    "    plt.scatter(x2, y2, color='sienna', marker='^', s=100, label='Materials Project')\n",
    "    plt.scatter([0.25, 0.33333333, 0.5],\n",
    "                [-0.125695, -0.1247125, -0.11877529],\n",
    "                color='red', marker='d', s=100, label='On Convex Hull')\n",
    "    plt.scatter(cubic_data[:, 0], cubic_data[:, 1], color='red', marker='s', s=100, label='Cubic')\n",
    "\n",
    "    plt.rc('font', family='Times New Roman')\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.xlabel(\"${m}/{m + n}$\", fontsize=18)\n",
    "    plt.ylabel(\"Formation Energy (eV / atom)\", fontsize=18)\n",
    "    plt.xlim(0, 1)\n",
    "    plt.ylim(-0.2, 0.3)\n",
    "\n",
    "    ax.set_xticks([0.142857, 0.25, 0.333333, 0.5, 0.666667, 0.75])\n",
    "    ax.set_yticks([-0.15, -0.1, -0.05, 0, 0.05, 0.1, 0.15, 0.2, 0.25])\n",
    "\n",
    "    plt.legend(['Elemental Substitution', 'Materials Project', 'On Convex Hull', 'Cubic'], prop={'size': 18})\n",
    "\n",
    "    plt.text(0.96, -0.118, 'GeTe', fontdict={'family': 'Times New Roman', 'size': 15})\n",
    "    plt.text(0.22, -0.15, '$\\mathregular{Ge_1Sb_6Te_{10}}$', fontdict={'family': 'Times New Roman', 'size': 15})\n",
    "    plt.text(0.305, -0.15, '$\\mathregular{Ge_1Sb_4Te_7}$', fontdict={'family': 'Times New Roman', 'size': 15})\n",
    "    plt.text(0.305, -0.15, '$\\mathregular{Ge_1Sb_4Te_7}$', fontdict={'family': 'Times New Roman', 'size': 15})\n",
    "    plt.text(0.47, -0.145, '$\\mathregular{Ge_1Sb_2Te_4}$', fontdict={'family': 'Times New Roman', 'size': 15})\n",
    "    plt.text(0.635, -0.135, '$\\mathregular{Ge_2Sb_2Te_5}$', fontdict={'family': 'Times New Roman', 'size': 15})\n",
    "    plt.text(0.005, -0.138, '$\\mathregular{Sb_2Te_3}$', fontdict={'family': 'Times New Roman', 'size': 15})\n",
    "\n",
    "    for i in simplices:\n",
    "        # print(hull_data[i, 0])\n",
    "        # print(hull_data[i, 1])\n",
    "        plt.plot(hull_data[i, 0], hull_data[i, 1], c='gold', linewidth=3)\n",
    "\n",
    "    for i in range(len(cubic_data) - 1):\n",
    "        plt.plot(cubic_data[[i, i + 1], 0], cubic_data[[i, i + 1], 1], c='gold', linewidth=3)\n",
    "\n",
    "    plt.savefig('Elemental_Substitution_Convex_Hull.png', dpi=1200)\n",
    "    plt.show()\n"
   ],
   "id": "576488ffe0a7f376"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if __name__ == '__main__':\n",
    "    path = r'~'\n",
    "    file = os.path.join(path, r'valid_data.csv')\n",
    "    data_extraction()\n",
    "    data_processing(os.path.join(path, r'EleSub_dataset.csv'))\n",
    "    convex_hull(os.path.join(path, r'valid_data.csv'))\n",
    "    select_data(os.path.join(path, r'EleSub_Energy_above_Hull.csv'))\n",
    "    plot_convex_hull(file)\n"
   ],
   "id": "593f654e54931995"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
